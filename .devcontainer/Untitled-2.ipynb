{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div></div><div></div><div><strong>Installed Packages</strong><ul><li><span>Microsoft.Spark, 2.1.0</span></li></ul></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Loading extensions from `Microsoft.Data.Analysis.Interactive.dll`"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-03-01T13:33:37.2244035Z] [02e1cd668e4c] [Info] [ConfigurationService] 'DOTNETBACKEND_PORT' environment variable is not set.\n",
      "[2022-03-01T13:33:37.2266517Z] [02e1cd668e4c] [Info] [ConfigurationService] Using port 5567 for connection.\n",
      "[2022-03-01T13:33:37.2272630Z] [02e1cd668e4c] [Info] [JvmBridge] JvMBridge port is 5567\n",
      "[2022-03-01T13:33:37.2279088Z] [02e1cd668e4c] [Info] [JvmBridge] The number of JVM backend thread is set to 10. The max number of concurrent sockets in JvmBridge is set to 7.\n",
      "org.apache.kafka.common.security.plain.PlainLoginModule required username=\"$ConnectionString\" password=\"Endpoint=sb://evhns-timeseries-timeseries-u-001.servicebus.windows.net/;SharedAccessKeyName=listen;SharedAccessKey=lGW5ENgWGFeRhNNBhPkq4uAYrebkWhSTa0ZbvafB9cw=;EntityPath=received-timeseries\";\n",
      "[2022-03-01T13:33:41.6816339Z] [02e1cd668e4c] [Info] [CallbackServer] Starting CallbackServer.\n",
      "[2022-03-01T13:33:41.7116472Z] [02e1cd668e4c] [Info] [CallbackServer] Started CallbackServer on 127.0.0.1:42987\n",
      "[2022-03-01T13:33:47.8712394Z] [02e1cd668e4c] [Info] [CallbackConnection] [1] Connected with RemoteEndPoint: 127.0.0.1:59298\n",
      "[2022-03-01T13:33:47.8730319Z] [02e1cd668e4c] [Info] [CallbackServer] Pool snapshot: [NumThreads:1], [NumConnections:1]\n",
      "[2022-03-01T13:33:47.8764689Z] [02e1cd668e4c] [Info] [CallbackConnection] [1] Received request for callback id: 1, callback handler: Microsoft.Spark.Interop.Ipc.ForeachBatchCallbackHandler\n",
      "[2022-03-01T13:33:47.8768773Z] [02e1cd668e4c] [Debug] [CallbackConnection] [1] Received END_OF_STREAM signal.\n",
      "Hello\n",
      "+---+-----+-----+---------+------+---------+-------------+\n",
      "|key|value|topic|partition|offset|timestamp|timestampType|\n",
      "+---+-----+-----+---------+------+---------+-------------+\n",
      "+---+-----+-----+---------+------+---------+-------------+\n",
      "\n",
      "[2022-03-01T13:33:48.2640324Z] [02e1cd668e4c] [Error] [JvmBridge] JVM method execution failed: Nonstatic method 'col' failed for class '20' when called with 1 arguments ([Index=1, Type=String, Value=enqueuedTime], )\n",
      "[2022-03-01T13:33:48.2642330Z] [02e1cd668e4c] [Error] [JvmBridge] org.apache.spark.sql.AnalysisException: Cannot resolve column name \"enqueuedTime\" among (key, value, topic, partition, offset, timestamp, timestampType)\n",
      "\tat org.apache.spark.sql.errors.QueryCompilationErrors$.cannotResolveColumnNameAmongFieldsError(QueryCompilationErrors.scala:2261)\n",
      "\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$resolveException(Dataset.scala:258)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$resolve$1(Dataset.scala:250)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.Dataset.resolve(Dataset.scala:250)\n",
      "\tat org.apache.spark.sql.Dataset.col(Dataset.scala:1352)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.spark.api.dotnet.DotnetBackendHandler.handleMethodCall(DotnetBackendHandler.scala:165)\n",
      "\tat org.apache.spark.api.dotnet.DotnetBackendHandler.$anonfun$handleBackendRequest$2(DotnetBackendHandler.scala:105)\n",
      "\tat org.apache.spark.api.dotnet.ThreadPool$$anon$1.run(ThreadPool.scala:34)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "[2022-03-01T13:33:48.2649406Z] [02e1cd668e4c] [Exception] [JvmBridge] JVM method execution failed: Nonstatic method 'col' failed for class '20' when called with 1 arguments ([Index=1, Type=String, Value=enqueuedTime], )\n",
      "   at Microsoft.Spark.Interop.Ipc.JvmBridge.CallJavaMethod(Boolean isStatic, Object classNameOrJvmObjectReference, String methodName, Object[] args)\n",
      "[2022-03-01T13:33:48.2653592Z] [02e1cd668e4c] [Error] [CallbackConnection] [1] ProcessStream() failed with exception: System.Exception: JVM method execution failed: Nonstatic method 'col' failed for class '20' when called with 1 arguments ([Index=1, Type=String, Value=enqueuedTime], )\n",
      " ---> Microsoft.Spark.JvmException: org.apache.spark.sql.AnalysisException: Cannot resolve column name \"enqueuedTime\" among (key, value, topic, partition, offset, timestamp, timestampType)\n",
      "\tat org.apache.spark.sql.errors.QueryCompilationErrors$.cannotResolveColumnNameAmongFieldsError(QueryCompilationErrors.scala:2261)\n",
      "\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$resolveException(Dataset.scala:258)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$resolve$1(Dataset.scala:250)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.Dataset.resolve(Dataset.scala:250)\n",
      "\tat org.apache.spark.sql.Dataset.col(Dataset.scala:1352)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.spark.api.dotnet.DotnetBackendHandler.handleMethodCall(DotnetBackendHandler.scala:165)\n",
      "\tat org.apache.spark.api.dotnet.DotnetBackendHandler.$anonfun$handleBackendRequest$2(DotnetBackendHandler.scala:105)\n",
      "\tat org.apache.spark.api.dotnet.ThreadPool$$anon$1.run(ThreadPool.scala:34)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "   --- End of inner exception stack trace ---\n",
      "   at Microsoft.Spark.Interop.Ipc.JvmBridge.CallJavaMethod(Boolean isStatic, Object classNameOrJvmObjectReference, String methodName, Object[] args)\n",
      "   at Microsoft.Spark.Interop.Ipc.JvmBridge.CallJavaMethod(Boolean isStatic, Object classNameOrJvmObjectReference, String methodName, Object arg0)\n",
      "   at Microsoft.Spark.Interop.Ipc.JvmBridge.CallNonStaticJavaMethod(JvmObjectReference jvmObject, String methodName, Object arg0)\n",
      "   at Microsoft.Spark.Interop.Ipc.JvmObjectReference.Invoke(String methodName, Object arg0)\n",
      "   at Microsoft.Spark.Sql.DataFrame.get_Item(String columnName)\n",
      "   at Submission#2.ProcessEventhubItem(DataFrame df, Int64 epochId, String timeseriesUnprocessedPath)\n",
      "   at Submission#2.<<Initialize>>b__0_0(DataFrame df, Int64 epochId)\n",
      "   at Microsoft.Spark.Interop.Ipc.ForeachBatchCallbackHandler.Run(Stream inputStream)\n",
      "   at Microsoft.Spark.Interop.Ipc.CallbackConnection.ProcessStream(Stream inputStream, Stream outputStream, Boolean& readComplete)\n",
      "[2022-03-01T13:33:48.2657302Z] [02e1cd668e4c] [Error] [CallbackConnection] [1] Exiting with exception: System.Exception: JVM method execution failed: Nonstatic method 'col' failed for class '20' when called with 1 arguments ([Index=1, Type=String, Value=enqueuedTime], )\n",
      " ---> Microsoft.Spark.JvmException: org.apache.spark.sql.AnalysisException: Cannot resolve column name \"enqueuedTime\" among (key, value, topic, partition, offset, timestamp, timestampType)\n",
      "\tat org.apache.spark.sql.errors.QueryCompilationErrors$.cannotResolveColumnNameAmongFieldsError(QueryCompilationErrors.scala:2261)\n",
      "\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$resolveException(Dataset.scala:258)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$resolve$1(Dataset.scala:250)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.Dataset.resolve(Dataset.scala:250)\n",
      "\tat org.apache.spark.sql.Dataset.col(Dataset.scala:1352)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.spark.api.dotnet.DotnetBackendHandler.handleMethodCall(DotnetBackendHandler.scala:165)\n",
      "\tat org.apache.spark.api.dotnet.DotnetBackendHandler.$anonfun$handleBackendRequest$2(DotnetBackendHandler.scala:105)\n",
      "\tat org.apache.spark.api.dotnet.ThreadPool$$anon$1.run(ThreadPool.scala:34)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "   --- End of inner exception stack trace ---\n",
      "   at Microsoft.Spark.Interop.Ipc.JvmBridge.CallJavaMethod(Boolean isStatic, Object classNameOrJvmObjectReference, String methodName, Object[] args)\n",
      "   at Microsoft.Spark.Interop.Ipc.JvmBridge.CallJavaMethod(Boolean isStatic, Object classNameOrJvmObjectReference, String methodName, Object arg0)\n",
      "   at Microsoft.Spark.Interop.Ipc.JvmBridge.CallNonStaticJavaMethod(JvmObjectReference jvmObject, String methodName, Object arg0)\n",
      "   at Microsoft.Spark.Interop.Ipc.JvmObjectReference.Invoke(String methodName, Object arg0)\n",
      "   at Microsoft.Spark.Sql.DataFrame.get_Item(String columnName)\n",
      "   at Submission#2.ProcessEventhubItem(DataFrame df, Int64 epochId, String timeseriesUnprocessedPath)\n",
      "   at Submission#2.<<Initialize>>b__0_0(DataFrame df, Int64 epochId)\n",
      "   at Microsoft.Spark.Interop.Ipc.ForeachBatchCallbackHandler.Run(Stream inputStream)\n",
      "   at Microsoft.Spark.Interop.Ipc.CallbackConnection.ProcessStream(Stream inputStream, Stream outputStream, Boolean& readComplete)\n",
      "   at Microsoft.Spark.Interop.Ipc.CallbackConnection.Run(CancellationToken token)\n",
      "[2022-03-01T13:33:48.2661488Z] [02e1cd668e4c] [Info] [CallbackConnection] [1] Finished running 0 callback(s).\n",
      "[2022-03-01T13:33:48.3360890Z] [02e1cd668e4c] [Error] [JvmBridge] JVM method execution failed: Nonstatic method 'awaitTermination' failed for class '19' when called with no arguments\n",
      "[2022-03-01T13:33:48.3364131Z] [02e1cd668e4c] [Error] [JvmBridge] org.apache.spark.sql.streaming.StreamingQueryException: Error while verifying end of stream.\n",
      "=== Streaming Query ===\n",
      "Identifier: [id = be3dddbe-9aa7-414e-b437-5173f26b9e5c, runId = 54af6c6f-131e-4ff3-b118-da3963cea92e]\n",
      "Current Committed Offsets: {}\n",
      "Current Available Offsets: {KafkaV2[Subscribe[received-timeseries]]: {\"received-timeseries\":{\"2\":8,\"1\":10,\"3\":18,\"0\":14}}}\n",
      "\n",
      "Current State: ACTIVE\n",
      "Thread State: RUNNABLE\n",
      "\n",
      "Logical Plan:\n",
      "StreamingDataSourceV2Relation [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13], org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan@6d025ea5, KafkaV2[Subscribe[received-timeseries]]\n",
      "\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:325)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:209)\n",
      "Caused by: java.lang.Exception: Error while verifying end of stream.\n",
      "\tat org.apache.spark.api.dotnet.CallbackConnection.send(CallbackConnection.scala:61)\n",
      "\tat org.apache.spark.api.dotnet.CallbackClient.send(CallbackClient.scala:32)\n",
      "\tat org.apache.spark.sql.api.dotnet.DotnetForeachBatchFunction.call(DotnetForeachBatch.scala:18)\n",
      "\tat org.apache.spark.sql.api.dotnet.DotnetForeachBatchHelper$.$anonfun$callForeachBatch$1(DotnetForeachBatch.scala:31)\n",
      "\tat org.apache.spark.sql.api.dotnet.DotnetForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(DotnetForeachBatch.scala:31)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:35)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:600)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:598)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:375)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:373)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:69)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:598)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:228)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:375)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:373)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:69)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:193)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:57)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:187)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:303)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:286)\n",
      "\t... 1 more\n",
      "Caused by: org.apache.spark.api.dotnet.DotnetException: System.Exception: JVM method execution failed: Nonstatic method 'col' failed for class '20' when called with 1 arguments ([Index=1, Type=String, Value=enqueuedTime], )\n",
      " ---> Microsoft.Spark.JvmException: org.apache.spark.sql.AnalysisException: Cannot resolve column name \"enqueuedTime\" among (key, value, topic, partition, offset, timestamp, timestampType)\n",
      "\tat org.apache.spark.sql.errors.QueryCompilationErrors$.cannotResolveColumnNameAmongFieldsError(QueryCompilationErrors.scala:2261)\n",
      "\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$resolveException(Dataset.scala:258)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$resolve$1(Dataset.scala:250)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.Dataset.resolve(Dataset.scala:250)\n",
      "\tat org.apache.spark.sql.Dataset.col(Dataset.scala:1352)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.spark.api.dotnet.DotnetBackendHandler.handleMethodCall(DotnetBackendHandler.scala:165)\n",
      "\tat org.apache.spark.api.dotnet.DotnetBackendHandler.$anonfun$handleBackendRequest$2(DotnetBackendHandler.scala:105)\n",
      "\tat org.apache.spark.api.dotnet.ThreadPool$$anon$1.run(ThreadPool.scala:34)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "   --- End of inner exception stack trace ---\n",
      "   at Microsoft.Spark.Interop.Ipc.JvmBridge.CallJavaMethod(Boolean isStatic, Object classNameOrJvmObjectReference, String methodName, Object[] args)\n",
      "   at Microsoft.Spark.Interop.Ipc.JvmBridge.CallJavaMethod(Boolean isStatic, Object classNameOrJvmObjectReference, String methodName, Object arg0)\n",
      "   at Microsoft.Spark.Interop.Ipc.JvmBridge.CallNonStaticJavaMethod(JvmObjectReference jvmObject, String methodName, Object arg0)\n",
      "   at Microsoft.Spark.Interop.Ipc.JvmObjectReference.Invoke(String methodName, Object arg0)\n",
      "   at Microsoft.Spark.Sql.DataFrame.get_Item(String columnName)\n",
      "   at Submission#2.ProcessEventhubItem(DataFrame df, Int64 epochId, String timeseriesUnprocessedPath)\n",
      "   at Submission#2.<<Initialize>>b__0_0(DataFrame df, Int64 epochId)\n",
      "   at Microsoft.Spark.Interop.Ipc.ForeachBatchCallbackHandler.Run(Stream inputStream)\n",
      "   at Microsoft.Spark.Interop.Ipc.CallbackConnection.ProcessStream(Stream inputStream, Stream outputStream, Boolean& readComplete)\n",
      "\tat org.apache.spark.api.dotnet.CallbackConnection.readFlag(CallbackConnection.scala:101)\n",
      "\tat org.apache.spark.api.dotnet.CallbackConnection.send(CallbackConnection.scala:50)\n",
      "\t... 29 more\n",
      "\n",
      "[2022-03-01T13:33:48.3367951Z] [02e1cd668e4c] [Exception] [JvmBridge] JVM method execution failed: Nonstatic method 'awaitTermination' failed for class '19' when called with no arguments\n",
      "   at Microsoft.Spark.Interop.Ipc.JvmBridge.CallJavaMethod(Boolean isStatic, Object classNameOrJvmObjectReference, String methodName, Object[] args)\n"
     ]
    },
    {
     "ename": "Error",
     "evalue": "System.Exception: JVM method execution failed: Nonstatic method 'awaitTermination' failed for class '19' when called with no arguments\n ---> Microsoft.Spark.JvmException: org.apache.spark.sql.streaming.StreamingQueryException: Error while verifying end of stream.\n=== Streaming Query ===\nIdentifier: [id = be3dddbe-9aa7-414e-b437-5173f26b9e5c, runId = 54af6c6f-131e-4ff3-b118-da3963cea92e]\nCurrent Committed Offsets: {}\nCurrent Available Offsets: {KafkaV2[Subscribe[received-timeseries]]: {\"received-timeseries\":{\"2\":8,\"1\":10,\"3\":18,\"0\":14}}}\n\nCurrent State: ACTIVE\nThread State: RUNNABLE\n\nLogical Plan:\nStreamingDataSourceV2Relation [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13], org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan@6d025ea5, KafkaV2[Subscribe[received-timeseries]]\n\n\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:325)\n\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:209)\nCaused by: java.lang.Exception: Error while verifying end of stream.\n\tat org.apache.spark.api.dotnet.CallbackConnection.send(CallbackConnection.scala:61)\n\tat org.apache.spark.api.dotnet.CallbackClient.send(CallbackClient.scala:32)\n\tat org.apache.spark.sql.api.dotnet.DotnetForeachBatchFunction.call(DotnetForeachBatch.scala:18)\n\tat org.apache.spark.sql.api.dotnet.DotnetForeachBatchHelper$.$anonfun$callForeachBatch$1(DotnetForeachBatch.scala:31)\n\tat org.apache.spark.sql.api.dotnet.DotnetForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(DotnetForeachBatch.scala:31)\n\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:35)\n\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:600)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:598)\n\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:375)\n\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:373)\n\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:69)\n\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:598)\n\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:228)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:375)\n\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:373)\n\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:69)\n\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:193)\n\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:57)\n\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:187)\n\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:303)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:286)\n\t... 1 more\nCaused by: org.apache.spark.api.dotnet.DotnetException: System.Exception: JVM method execution failed: Nonstatic method 'col' failed for class '20' when called with 1 arguments ([Index=1, Type=String, Value=enqueuedTime], )\n ---> Microsoft.Spark.JvmException: org.apache.spark.sql.AnalysisException: Cannot resolve column name \"enqueuedTime\" among (key, value, topic, partition, offset, timestamp, timestampType)\n\tat org.apache.spark.sql.errors.QueryCompilationErrors$.cannotResolveColumnNameAmongFieldsError(QueryCompilationErrors.scala:2261)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$resolveException(Dataset.scala:258)\n\tat org.apache.spark.sql.Dataset.$anonfun$resolve$1(Dataset.scala:250)\n\tat scala.Option.getOrElse(Option.scala:189)\n\tat org.apache.spark.sql.Dataset.resolve(Dataset.scala:250)\n\tat org.apache.spark.sql.Dataset.col(Dataset.scala:1352)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat org.apache.spark.api.dotnet.DotnetBackendHandler.handleMethodCall(DotnetBackendHandler.scala:165)\n\tat org.apache.spark.api.dotnet.DotnetBackendHandler.$anonfun$handleBackendRequest$2(DotnetBackendHandler.scala:105)\n\tat org.apache.spark.api.dotnet.ThreadPool$$anon$1.run(ThreadPool.scala:34)\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\n   --- End of inner exception stack trace ---\n   at Microsoft.Spark.Interop.Ipc.JvmBridge.CallJavaMethod(Boolean isStatic, Object classNameOrJvmObjectReference, String methodName, Object[] args)\n   at Microsoft.Spark.Interop.Ipc.JvmBridge.CallJavaMethod(Boolean isStatic, Object classNameOrJvmObjectReference, String methodName, Object arg0)\n   at Microsoft.Spark.Interop.Ipc.JvmBridge.CallNonStaticJavaMethod(JvmObjectReference jvmObject, String methodName, Object arg0)\n   at Microsoft.Spark.Interop.Ipc.JvmObjectReference.Invoke(String methodName, Object arg0)\n   at Microsoft.Spark.Sql.DataFrame.get_Item(String columnName)\n   at Submission#2.ProcessEventhubItem(DataFrame df, Int64 epochId, String timeseriesUnprocessedPath)\n   at Submission#2.<<Initialize>>b__0_0(DataFrame df, Int64 epochId)\n   at Microsoft.Spark.Interop.Ipc.ForeachBatchCallbackHandler.Run(Stream inputStream)\n   at Microsoft.Spark.Interop.Ipc.CallbackConnection.ProcessStream(Stream inputStream, Stream outputStream, Boolean& readComplete)\n\tat org.apache.spark.api.dotnet.CallbackConnection.readFlag(CallbackConnection.scala:101)\n\tat org.apache.spark.api.dotnet.CallbackConnection.send(CallbackConnection.scala:50)\n\t... 29 more\n\n   --- End of inner exception stack trace ---\n   at Microsoft.Spark.Interop.Ipc.JvmBridge.CallJavaMethod(Boolean isStatic, Object classNameOrJvmObjectReference, String methodName, Object[] args)\n   at Microsoft.Spark.Interop.Ipc.JvmBridge.CallNonStaticJavaMethod(JvmObjectReference jvmObject, String methodName, Object[] args)\n   at Microsoft.Spark.Interop.Ipc.JvmObjectReference.Invoke(String methodName, Object[] args)\n   at Microsoft.Spark.Sql.Streaming.StreamingQuery.AwaitTermination()\n   at Submission#2.<<Initialize>>d__0.MoveNext()\n--- End of stack trace from previous location ---\n   at Microsoft.CodeAnalysis.Scripting.ScriptExecutionState.RunSubmissionsAsync[TResult](ImmutableArray`1 precedingExecutors, Func`2 currentExecutor, StrongBox`1 exceptionHolderOpt, Func`2 catchExceptionOpt, CancellationToken cancellationToken)",
     "output_type": "error",
     "traceback": [
      "System.Exception: JVM method execution failed: Nonstatic method 'awaitTermination' failed for class '19' when called with no arguments\n",
      " ---> Microsoft.Spark.JvmException: org.apache.spark.sql.streaming.StreamingQueryException: Error while verifying end of stream.\n",
      "=== Streaming Query ===\n",
      "Identifier: [id = be3dddbe-9aa7-414e-b437-5173f26b9e5c, runId = 54af6c6f-131e-4ff3-b118-da3963cea92e]\n",
      "Current Committed Offsets: {}\n",
      "Current Available Offsets: {KafkaV2[Subscribe[received-timeseries]]: {\"received-timeseries\":{\"2\":8,\"1\":10,\"3\":18,\"0\":14}}}\n",
      "\n",
      "Current State: ACTIVE\n",
      "Thread State: RUNNABLE\n",
      "\n",
      "Logical Plan:\n",
      "StreamingDataSourceV2Relation [key#7, value#8, topic#9, partition#10, offset#11L, timestamp#12, timestampType#13], org.apache.spark.sql.kafka010.KafkaSourceProvider$KafkaScan@6d025ea5, KafkaV2[Subscribe[received-timeseries]]\n",
      "\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:325)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution$$anon$1.run(StreamExecution.scala:209)\n",
      "Caused by: java.lang.Exception: Error while verifying end of stream.\n",
      "\tat org.apache.spark.api.dotnet.CallbackConnection.send(CallbackConnection.scala:61)\n",
      "\tat org.apache.spark.api.dotnet.CallbackClient.send(CallbackClient.scala:32)\n",
      "\tat org.apache.spark.sql.api.dotnet.DotnetForeachBatchFunction.call(DotnetForeachBatch.scala:18)\n",
      "\tat org.apache.spark.sql.api.dotnet.DotnetForeachBatchHelper$.$anonfun$callForeachBatch$1(DotnetForeachBatch.scala:31)\n",
      "\tat org.apache.spark.sql.api.dotnet.DotnetForeachBatchHelper$.$anonfun$callForeachBatch$1$adapted(DotnetForeachBatch.scala:31)\n",
      "\tat org.apache.spark.sql.execution.streaming.sources.ForeachBatchSink.addBatch(ForeachBatchSink.scala:35)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$17(MicroBatchExecution.scala:600)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runBatch$16(MicroBatchExecution.scala:598)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:375)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:373)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:69)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runBatch(MicroBatchExecution.scala:598)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$2(MicroBatchExecution.scala:228)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken(ProgressReporter.scala:375)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProgressReporter.reportTimeTaken$(ProgressReporter.scala:373)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.reportTimeTaken(StreamExecution.scala:69)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.$anonfun$runActivatedStream$1(MicroBatchExecution.scala:193)\n",
      "\tat org.apache.spark.sql.execution.streaming.ProcessingTimeExecutor.execute(TriggerExecutor.scala:57)\n",
      "\tat org.apache.spark.sql.execution.streaming.MicroBatchExecution.runActivatedStream(MicroBatchExecution.scala:187)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.$anonfun$runStream$1(StreamExecution.scala:303)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n",
      "\tat org.apache.spark.sql.execution.streaming.StreamExecution.org$apache$spark$sql$execution$streaming$StreamExecution$$runStream(StreamExecution.scala:286)\n",
      "\t... 1 more\n",
      "Caused by: org.apache.spark.api.dotnet.DotnetException: System.Exception: JVM method execution failed: Nonstatic method 'col' failed for class '20' when called with 1 arguments ([Index=1, Type=String, Value=enqueuedTime], )\n",
      " ---> Microsoft.Spark.JvmException: org.apache.spark.sql.AnalysisException: Cannot resolve column name \"enqueuedTime\" among (key, value, topic, partition, offset, timestamp, timestampType)\n",
      "\tat org.apache.spark.sql.errors.QueryCompilationErrors$.cannotResolveColumnNameAmongFieldsError(QueryCompilationErrors.scala:2261)\n",
      "\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$resolveException(Dataset.scala:258)\n",
      "\tat org.apache.spark.sql.Dataset.$anonfun$resolve$1(Dataset.scala:250)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.Dataset.resolve(Dataset.scala:250)\n",
      "\tat org.apache.spark.sql.Dataset.col(Dataset.scala:1352)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat org.apache.spark.api.dotnet.DotnetBackendHandler.handleMethodCall(DotnetBackendHandler.scala:165)\n",
      "\tat org.apache.spark.api.dotnet.DotnetBackendHandler.$anonfun$handleBackendRequest$2(DotnetBackendHandler.scala:105)\n",
      "\tat org.apache.spark.api.dotnet.ThreadPool$$anon$1.run(ThreadPool.scala:34)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "   --- End of inner exception stack trace ---\n",
      "   at Microsoft.Spark.Interop.Ipc.JvmBridge.CallJavaMethod(Boolean isStatic, Object classNameOrJvmObjectReference, String methodName, Object[] args)\n",
      "   at Microsoft.Spark.Interop.Ipc.JvmBridge.CallJavaMethod(Boolean isStatic, Object classNameOrJvmObjectReference, String methodName, Object arg0)\n",
      "   at Microsoft.Spark.Interop.Ipc.JvmBridge.CallNonStaticJavaMethod(JvmObjectReference jvmObject, String methodName, Object arg0)\n",
      "   at Microsoft.Spark.Interop.Ipc.JvmObjectReference.Invoke(String methodName, Object arg0)\n",
      "   at Microsoft.Spark.Sql.DataFrame.get_Item(String columnName)\n",
      "   at Submission#2.ProcessEventhubItem(DataFrame df, Int64 epochId, String timeseriesUnprocessedPath)\n",
      "   at Submission#2.<<Initialize>>b__0_0(DataFrame df, Int64 epochId)\n",
      "   at Microsoft.Spark.Interop.Ipc.ForeachBatchCallbackHandler.Run(Stream inputStream)\n",
      "   at Microsoft.Spark.Interop.Ipc.CallbackConnection.ProcessStream(Stream inputStream, Stream outputStream, Boolean& readComplete)\n",
      "\tat org.apache.spark.api.dotnet.CallbackConnection.readFlag(CallbackConnection.scala:101)\n",
      "\tat org.apache.spark.api.dotnet.CallbackConnection.send(CallbackConnection.scala:50)\n",
      "\t... 29 more\n",
      "\n",
      "   --- End of inner exception stack trace ---\n",
      "   at Microsoft.Spark.Interop.Ipc.JvmBridge.CallJavaMethod(Boolean isStatic, Object classNameOrJvmObjectReference, String methodName, Object[] args)\n",
      "   at Microsoft.Spark.Interop.Ipc.JvmBridge.CallNonStaticJavaMethod(JvmObjectReference jvmObject, String methodName, Object[] args)\n",
      "   at Microsoft.Spark.Interop.Ipc.JvmObjectReference.Invoke(String methodName, Object[] args)\n",
      "   at Microsoft.Spark.Sql.Streaming.StreamingQuery.AwaitTermination()\n",
      "   at Submission#2.<<Initialize>>d__0.MoveNext()\n",
      "--- End of stack trace from previous location ---\n",
      "   at Microsoft.CodeAnalysis.Scripting.ScriptExecutionState.RunSubmissionsAsync[TResult](ImmutableArray`1 precedingExecutors, Func`2 currentExecutor, StrongBox`1 exceptionHolderOpt, Func`2 catchExceptionOpt, CancellationToken cancellationToken)"
     ]
    }
   ],
   "source": [
    "#r \"nuget:Microsoft.Spark\"\n",
    "using System;\n",
    "using System.Collections.Generic;\n",
    "using Microsoft.Spark.Sql;\n",
    "using Microsoft.Spark.Sql.Types;\n",
    "\n",
    "Environment.SetEnvironmentVariable(\"EVENT_HUB_CONNECTION_STRING\", \"Endpoint=sb://evhns-timeseries-timeseries-u-001.servicebus.windows.net/;SharedAccessKeyName=listen;SharedAccessKey=lGW5ENgWGFeRhNNBhPkq4uAYrebkWhSTa0ZbvafB9cw=;EntityPath=received-timeseries\");\n",
    "/////////////////////////////////////////////////////\n",
    "\n",
    "var spark = SparkSession.Builder().GetOrCreate();\n",
    "var timeseries_unprocessed_path = \"TODO\";\n",
    "\n",
    "var eventHubConnectionString = Environment.GetEnvironmentVariable(\"EVENT_HUB_CONNECTION_STRING\");\n",
    "\n",
    "// TODO BJARKE: Extract hostname from connection string: Endpoint=sb://evhns-integrationstest-u-002.servicebus.windows.net/;SharedAccessKeyName=RootManageSharedAccessKey;SharedAccessKey=*******\n",
    "string bootstrapServers = \"evhns-timeseries-timeseries-u-001.servicebus.windows.net:9093\"; // 9093 is the port used to communicate with Event Hubs, see [troubleshooting guide](https://docs.microsoft.com/azure/event-hubs/troubleshooting-guide)\n",
    "string eh_sasl = $\"org.apache.kafka.common.security.plain.PlainLoginModule required username=\\\"$ConnectionString\\\" password=\\\"{eventHubConnectionString}\\\";\";\n",
    "Console.WriteLine(eh_sasl);\n",
    "\n",
    "var streamingDf = spark\n",
    "    .ReadStream()\n",
    "    .Format(\"kafka\")\n",
    "    .Option(\"kafka.bootstrap.servers\", bootstrapServers)\n",
    "    .Option(\"subscribe\", \"received-timeseries\")\n",
    "    .Option(\"kafka.sasl.mechanism\", \"PLAIN\")\n",
    "    .Option(\"kafka.security.protocol\", \"SASL_SSL\")\n",
    "    .Option(\"kafka.sasl.jaas.config\", eh_sasl)\n",
    "    .Option(\"kafka.request.timeout.ms\", \"60000\")\n",
    "    .Option(\"kafka.session.timeout.ms\", \"60000\")\n",
    "    .Option(\"failOnDataLoss\", \"false\")\n",
    "    .Load();\n",
    "\n",
    "    var checkpointPath = \"received_time_series_checkpoint\";\n",
    "    //var checkpointPath = $\"abfss://{delta_lake_container_name}@{storage_account_name}.dfs.core.windows.net/checkpoint\"\n",
    "     streamingDf\n",
    "         .WriteStream()\n",
    "    //     //.Option(\"checkpointLocation\", checkpointPath)\n",
    "    //     // TODO: Trigger setup\n",
    "         .ForeachBatch((df, epochId) => ProcessEventhubItem(df, epochId, timeseries_unprocessed_path))\n",
    "         .Start().AwaitTermination();\n",
    "\n",
    "  //  var dfWrite = streamingDf.WriteStream().OutputMode(\"append\").Format(\"console\").Start();\n",
    "    //dfWrite.AwaitTermination();\n",
    "    //spark.Stop();\n",
    "   \n",
    "    public static void ProcessEventhubItem(DataFrame df, long epochId, string timeseriesUnprocessedPath)\n",
    "    {\n",
    "        Console.WriteLine(\"Hello\");\n",
    "        if(df.Head(1).Count()>0){\n",
    "            df.Show();\n",
    "        }\n",
    "        // if (df == null) throw new ArgumentNullException(nameof(timeseriesUnprocessedPath));\n",
    "        // df = df\n",
    "        //     .WithColumn(\"year\", Functions.Year(df[\"enqueuedTime\"]))\n",
    "        //     .WithColumn(\"month\", Functions.Month(df[\"enqueuedTime\"]))\n",
    "        //     .WithColumn(\"day\", Functions.DayOfMonth(df[\"enqueuedTime\"]));\n",
    "        // // df\n",
    "        // //     .Write()\n",
    "        // //     .PartitionBy(\"year\", \"month\", \"day\")\n",
    "        // //     .Format(\"delta\")\n",
    "        // //     .Mode(SaveMode.Append)\n",
    "        // //     .Save(timeseries_unprocessed_path);\n",
    "        // df.Show();\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".NET (C#)",
   "language": "C#",
   "name": ".net-csharp"
  },
  "language_info": {
   "name": "C#"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
