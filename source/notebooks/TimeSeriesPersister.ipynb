{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   },
   "source": [
    "# Time Series Persister\n",
    "Usage:\n",
    "- Copy `TimeSeriesPersister.env.sample` to `TimeSeriesPersister.env`\n",
    "- Edit `TimeSeriesPersister.env` to match your environment\n",
    "- Execute the cells but only one of the _setup_ cells\n",
    "\n",
    "Tip: If you encounter problems running cells with spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read Configuration From `.env` File**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div></div><div></div><div><strong>Installed Packages</strong><ul><li><span>dotenv.net, 3.0.0</span></li><li><span>Microsoft.Spark, 2.1.0</span></li><li><span>Microsoft.Spark.Extensions.Delta, 2.1.0</span></li></ul></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Loading extensions from `Microsoft.Data.Analysis.Interactive.dll`"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#r \"nuget: dotenv.net, 3.0.0\"\n",
    "#r \"nuget:Microsoft.Spark\"\n",
    "#r \"nuget: Microsoft.Spark.Extensions.Delta, 2.1.0\"\n",
    "using System;\n",
    "using System.Collections.Generic;\n",
    "using Microsoft.Spark.Sql;\n",
    "using Microsoft.Spark.Sql.Streaming;\n",
    "using Microsoft.Spark.Sql.Types;\n",
    "using Microsoft.Spark.Extensions.Delta;\n",
    "using static Microsoft.Spark.Sql.Functions;\n",
    "using System.Text.RegularExpressions;\n",
    "using dotenv.net;\n",
    "\n",
    "var envVars = DotEnv.Fluent().WithEnvFiles(\"./TimeSeriesPersister.env\").Read();\n",
    "\n",
    "// Event hub (Kafka source)\n",
    "var eventHubConnectionString = envVars[\"EVENTHUB_CONNECTIONSTRING\"];\n",
    "var eventHubsNamespace = Regex.Match(eventHubConnectionString, \"sb://([^.]+).\").Groups[1].Value;\n",
    "var eventHubsInstance = Regex.Match(eventHubConnectionString, \"EntityPath=(.+)$\").Groups[1].Value;\n",
    "\n",
    "// Delta Table (sink)\n",
    "var storageAccountKey = envVars[\"STORAGE_ACCOUNT_KEY\"];\n",
    "var storageAccountName = envVars[\"STORAGE_ACCOUNT_NAME\"];\n",
    "var delta_lake_container_name = envVars[\"DELTA_LAKE_CONTAINER_NAME\"];\n",
    "var blobName = envVars[\"BLOB_NAME\"];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setup - local file system**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "var path = \"/workspaces/geh-timeseries/source/notebooks/__storage__/local_file_system/unprocessed-time-series\";\n",
    "\n",
    "var spark = SparkSession\n",
    "    .Builder()\n",
    "    .GetOrCreate();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setup - Azure blob storage gen 2 (abfs)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "var path = $\"abfss://{delta_lake_container_name}@{storageAccountName}.dfs.core.windows.net/{blobName}\";\n",
    "\n",
    "var spark = SparkSession\n",
    "    .Builder()\n",
    "    // Support Azure blob storage gen 2\n",
    "    .Config($\"fs.azure.account.key.{storageAccountName}.dfs.core.windows.net\", storageAccountKey)\n",
    "    .GetOrCreate();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setup - Azurite (wasb)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "var path = \"unprocessed_time_series\";\n",
    "\n",
    "var spark = SparkSession\n",
    "    .Builder()\n",
    "    // Support Azurite\n",
    "    .Config(\"spark.hadoop.fs.defaultFS\", \"wasb://container@azurite\")\n",
    "    .Config(\"spark.hadoop.fs.azure.storage.emulator.account.name\", \"azurite\")\n",
    "    .GetOrCreate();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Show Received Time Series**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- time-series: string (nullable = true)\n",
      "\n",
      "+----+-----+---+--------------------+\n",
      "|year|month|day|         time-series|\n",
      "+----+-----+---+--------------------+\n",
      "|2022|    3| 10|{\"Document\":{\"Id\"...|\n",
      "|2022|    3| 10|{\"Document\":{\"Id\"...|\n",
      "|2022|    3| 10|{\"Document\":{\"Id\"...|\n",
      "|2022|    3| 10|{\"Document\":{\"Id\"...|\n",
      "+----+-----+---+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "var receivedTimeSeries = spark.Read().Format(\"delta\").Load(path);\n",
    "\n",
    "receivedTimeSeries.PrintSchema();\n",
    "receivedTimeSeries.Show(100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Execute Job**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-03-10T12:51:47.8331646Z] [a901b8652663] [Info] [CallbackServer] Starting CallbackServer.\n",
      "[2022-03-10T12:51:47.8390189Z] [a901b8652663] [Info] [CallbackServer] Started CallbackServer on 127.0.0.1:46843\n",
      "[2022-03-10T12:51:54.9541685Z] [a901b8652663] [Info] [CallbackConnection] [1] Connected with RemoteEndPoint: 127.0.0.1:60062\n",
      "[2022-03-10T12:51:54.9574134Z] [a901b8652663] [Info] [CallbackServer] Pool snapshot: [NumThreads:1], [NumConnections:1]\n",
      "[2022-03-10T12:51:54.9630403Z] [a901b8652663] [Info] [CallbackConnection] [1] Received request for callback id: 1, callback handler: Microsoft.Spark.Interop.Ipc.ForeachBatchCallbackHandler\n",
      "[2022-03-10T12:51:54.9644108Z] [a901b8652663] [Debug] [CallbackConnection] [1] Received END_OF_STREAM signal.\n",
      "root\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- time-series: string (nullable = true)\n",
      "\n",
      "+----+-----+---+-----------+\n",
      "|year|month|day|time-series|\n",
      "+----+-----+---+-----------+\n",
      "+----+-----+---+-----------+\n",
      "\n",
      "[2022-03-10T12:52:02.7264080Z] [a901b8652663] [Info] [CallbackConnection] [1] Received request for callback id: 1, callback handler: Microsoft.Spark.Interop.Ipc.ForeachBatchCallbackHandler\n",
      "[2022-03-10T12:52:02.7272815Z] [a901b8652663] [Debug] [CallbackConnection] [1] Received END_OF_STREAM signal.\n",
      "root\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- time-series: string (nullable = true)\n",
      "\n",
      "+----+-----+---+--------------------+\n",
      "|year|month|day|         time-series|\n",
      "+----+-----+---+--------------------+\n",
      "|2022|    3| 10|{\"Document\":{\"Id\"...|\n",
      "+----+-----+---+--------------------+\n",
      "\n",
      "[2022-03-10T12:52:10.7105337Z] [a901b8652663] [Info] [CallbackConnection] [1] Received request for callback id: 1, callback handler: Microsoft.Spark.Interop.Ipc.ForeachBatchCallbackHandler\n",
      "[2022-03-10T12:52:10.7112028Z] [a901b8652663] [Debug] [CallbackConnection] [1] Received END_OF_STREAM signal.\n",
      "root\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- time-series: string (nullable = true)\n",
      "\n",
      "+----+-----+---+--------------------+\n",
      "|year|month|day|         time-series|\n",
      "+----+-----+---+--------------------+\n",
      "|2022|    3| 10|{\"Document\":{\"Id\"...|\n",
      "|2022|    3| 10|{\"Document\":{\"Id\"...|\n",
      "+----+-----+---+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// 9093 is the port used to communicate with Event Hubs, see [troubleshooting guide](https://docs.microsoft.com/azure/event-hubs/troubleshooting-guide)\n",
    "string bootstrapServers = $\"{eventHubsNamespace}.servicebus.windows.net:9093\";\n",
    "string eh_sasl = $\"org.apache.kafka.common.security.plain.PlainLoginModule required username=\\\"$ConnectionString\\\" password=\\\"{eventHubConnectionString}\\\";\";\n",
    "\n",
    "var streamingDf = spark\n",
    "    .ReadStream()\n",
    "    .Format(\"kafka\")\n",
    "    .Option(\"kafka.bootstrap.servers\", bootstrapServers)\n",
    "    .Option(\"subscribe\", eventHubsInstance)\n",
    "    .Option(\"kafka.sasl.mechanism\", \"PLAIN\")\n",
    "    .Option(\"kafka.security.protocol\", \"SASL_SSL\")\n",
    "    .Option(\"kafka.sasl.jaas.config\", eh_sasl)\n",
    "    .Option(\"kafka.request.timeout.ms\", \"60000\")\n",
    "    .Option(\"kafka.session.timeout.ms\", \"60000\")\n",
    "    //.Option(\"failOnDataLoss\", \"false\")\n",
    "    //.Option(\"checkpointLocation\", \"/tmp/kafka_cp.txt\")\n",
    "    .Load()\n",
    "    .WriteStream()\n",
    "    .Trigger(Trigger.ProcessingTime(2000))\n",
    "    .ForeachBatch((df, id) =>\n",
    "    {\n",
    "        df = df\n",
    "            .WithColumn(\"year\", Functions.Year(df[\"timestamp\"]))\n",
    "            .WithColumn(\"month\", Functions.Month(df[\"timestamp\"]))\n",
    "            .WithColumn(\"day\", Functions.DayOfMonth(df[\"timestamp\"]))\n",
    "            .WithColumn(\"time-series\", Functions.Col(\"value\").Cast(\"string\"))\n",
    "            .Select(\"year\", \"month\", \"day\", \"time-series\");\n",
    "\n",
    "        df.PrintSchema();\n",
    "        df.Show();\n",
    "\n",
    "        df\n",
    "            .Write()\n",
    "            .PartitionBy(\"year\", \"month\", \"day\")\n",
    "            .Format(\"delta\")\n",
    "            .Mode(SaveMode.Append)\n",
    "            .Save(path);\n",
    "    })\n",
    "    .Start();\n",
    "\n",
    "streamingDf.AwaitTermination();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".NET (C#)",
   "language": "C#",
   "name": ".net-csharp"
  },
  "language_info": {
   "name": "C#"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
