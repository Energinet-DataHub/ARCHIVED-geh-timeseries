{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   },
   "source": [
    "# Time Series Persister\n",
    "Usage:\n",
    "- Copy `TimeSeriesPersister.env.sample` to `TimeSeriesPersister.env`\n",
    "- Edit `TimeSeriesPersister.env` to match your environment\n",
    "- Execute the cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read Configuration From `.env` File**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "#r \"nuget: dotenv.net, 3.0.0\"\n",
    "using System.Text.RegularExpressions;\n",
    "using dotenv.net;\n",
    "\n",
    "var envVars = DotEnv.Fluent().WithEnvFiles(\"./TimeSeriesPersister.env\").Read();\n",
    "\n",
    "// Event hub (Kafka source)\n",
    "var eventHubConnectionString = envVars[\"EVENTHUB_CONNECTIONSTRING\"];\n",
    "var eventHubsNamespace = Regex.Match(eventHubConnectionString, \"sb://([^.]+).\").Groups[1].Value;\n",
    "var eventHubsInstance = Regex.Match(eventHubConnectionString, \"EntityPath=(.+)$\").Groups[1].Value;\n",
    "\n",
    "// Delta Table (sink)\n",
    "var storageAccountKey = envVars[\"STORAGE_ACCOUNT_KEY\"];\n",
    "var storageAccountName = envVars[\"STORAGE_ACCOUNT_NAME\"];\n",
    "var delta_lake_container_name = envVars[\"DELTA_LAKE_CONTAINER_NAME\"];\n",
    "var blobName = envVars[\"BLOB_NAME\"];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "#r \"nuget:Microsoft.Spark\"\n",
    "#r \"nuget: Microsoft.Spark.Extensions.Delta, 2.1.0\"\n",
    "using System;\n",
    "using System.Collections.Generic;\n",
    "using Microsoft.Spark.Sql;\n",
    "using Microsoft.Spark.Sql.Streaming;\n",
    "using Microsoft.Spark.Sql.Types;\n",
    "using Microsoft.Spark.Extensions.Delta;\n",
    "using static Microsoft.Spark.Sql.Functions;\n",
    "\n",
    "// 9093 is the port used to communicate with Event Hubs, see [troubleshooting guide](https://docs.microsoft.com/azure/event-hubs/troubleshooting-guide)\n",
    "string bootstrapServers = $\"{eventHubsNamespace}.servicebus.windows.net:9093\";\n",
    "string eh_sasl = $\"org.apache.kafka.common.security.plain.PlainLoginModule required username=\\\"$ConnectionString\\\" password=\\\"{eventHubConnectionString}\\\";\";\n",
    "//var path = $\"abfss://{delta_lake_container_name}@{storageAccountName}.dfs.core.windows.net/{blobName}\";\n",
    "var path = \"/workspaces/geh-timeseries/source/notebooks/__delta__/unprocessed-time-series\";\n",
    "\n",
    "var spark = SparkSession.Builder().Config($\"fs.azure.account.key.{storageAccountName}.dfs.core.windows.net\", storageAccountKey).GetOrCreate();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Show Received Time Series**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "var receivedTimeSeries = spark.Read().Format(\"delta\").Load(path);\n",
    "\n",
    "receivedTimeSeries.PrintSchema();\n",
    "receivedTimeSeries.Show(100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Execute Job**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "var streamingDf = spark\n",
    "    .ReadStream()\n",
    "    .Format(\"kafka\")\n",
    "    .Option(\"kafka.bootstrap.servers\", bootstrapServers)\n",
    "    .Option(\"subscribe\", eventHubsInstance)\n",
    "    .Option(\"kafka.sasl.mechanism\", \"PLAIN\")\n",
    "    .Option(\"kafka.security.protocol\", \"SASL_SSL\")\n",
    "    .Option(\"kafka.sasl.jaas.config\", eh_sasl)\n",
    "    .Option(\"kafka.request.timeout.ms\", \"60000\")\n",
    "    .Option(\"kafka.session.timeout.ms\", \"60000\")\n",
    "    //.Option(\"failOnDataLoss\", \"false\")\n",
    "    //.Option(\"checkpointLocation\", \"/tmp/kafka_cp.txt\")\n",
    "    .Load()\n",
    "    .WriteStream()\n",
    "    .Trigger(Trigger.ProcessingTime(2000))\n",
    "    .ForeachBatch((df, id) =>\n",
    "    {\n",
    "        df = df\n",
    "            .WithColumn(\"year\", Functions.Year(df[\"timestamp\"]))\n",
    "            .WithColumn(\"month\", Functions.Month(df[\"timestamp\"]))\n",
    "            .WithColumn(\"day\", Functions.DayOfMonth(df[\"timestamp\"]))\n",
    "            .WithColumn(\"time-series\", Functions.Col(\"value\").Cast(\"string\"))\n",
    "            .Select(\"year\", \"month\", \"day\", \"time-series\");\n",
    "\n",
    "        df.PrintSchema();\n",
    "        df.Show();\n",
    "\n",
    "        df\n",
    "            .Write()\n",
    "            .PartitionBy(\"year\", \"month\", \"day\")\n",
    "            .Format(\"delta\")\n",
    "            .Mode(SaveMode.Append)\n",
    "            .Save(path);\n",
    "    })\n",
    "    .Start();\n",
    "\n",
    "streamingDf.AwaitTermination();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".NET (C#)",
   "language": "C#",
   "name": ".net-csharp"
  },
  "language_info": {
   "name": "C#"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
